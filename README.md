# Natural-Language-Processing-In-game-Toxicity-Detection
Based on the CONDA dataset (a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection) from the University of Sydney NLP Group, 
we developed the stacked Bi-LSTM model with multi-head attention and CRF layer to perform in-game toxicity detection.
The best performance achieved 99.51% regarding the F1 score.
